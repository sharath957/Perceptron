# -*- coding: utf-8 -*-
"""11/09 .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1he5yK5jWbERREN21XV6TeMrAcYW6pb4k
"""

ROOT = '/content/drive/MyDrive/Colab Notebooks/ineuron live class working/Ineuron DL'

import os 


os.chdir(ROOT)

!ls

with open('test.txt','w') as f:
  f.writelines('hello colab')

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import joblib # FOR SAVING MY MODEL AS A BINARY FILE
from matplotlib.colors import ListedColormap

plt.style.use("fivethirtyeight") # THIS IS STYLE OF GRAPHS

np.random.randn(3)

np.ones((3,1))

class perceptron:
  def __init__(self,eta,epochs): 
    self.weights = np.random.randn(3) * 1e-4 # the 3 here is the three weights as per our theory. w0,w1,w2
    print(f'Initial weights before training: \n{self.weights}') # f here is called the f string method
    self.eta = eta ## Learning rate
    self.epochs = epochs
    

  def activationfunction(self,inputs,weights):
    z = np.dot(inputs,weights) # z = W * X
    return np.where(z > 0, 1, 0) 


  def fit(self,X,y):
    self.X = X
    self.y = y 

    X_with_bias = np.c_[self.X, -np.ones((len(self.X),1))] 
    print(f'X with bias:\n {X_with_bias}') 

    for epoch in range(self.epochs):
      print("--"*10) 
      print(f'for epoch: {epoch}')
      print('--'*10)

      y_hat = self.activationfunction(X_with_bias,self.weights) # forward propogation
      print(f'predicted value after forward pass: \n{y_hat}')
      self.error = self.y - y_hat
      print(f'error: \n{self.error}')  
      self.weights =  self.weights + self.eta * np.dot(X_with_bias.T,self.error) # Backward propogation
      print(f'updated weights after epcohs: \n{epoch}/{self.epochs} :  \n{self.weights}') 
      print('######'*3)  

  def predict(self,X):
    X_with_bias = np.c_[X, -np.ones((len(X),1))] 
    return self.activationfunction(X_with_bias,self.weights)
      
  def total_loss(self):
    total_loss = np.sum(self.error)
    print(f'total loss: {total_loss}')
    return total_loss

"""eta above is the learning rate.


The def activation function will take the inputs and weights. we are defining the inputs and weights here


def fit is the fit method we use in ML this is same. where we are giving the X and y to fit a model.


def predict is to predict the X 
"""

def prepare_data(df):
  X  = df.drop('y',axis = 1)
  y = df['y']
  return X, y

"""**AND**"""

AND = {
    'x1':[0,0,1,1],
    'x2':[0,1,0,1],
    'y':[0,0,0,1],
}

df = pd.DataFrame(AND)
df

X,y = prepare_data(df)

ETA = 0.3 # 0 and 1
EPOCHS = 10

model = perceptron(eta=ETA, epochs=EPOCHS)
model.fit(X, y)

_ = model.total_loss()

model.predict(X)

inputs = np.array([[1,1],[0,1]])
model.predict(inputs)

def save_model(model,filename):
  model_dir = 'model'
  os.makedirs(model_dir,exist_ok=True) # ONLY CREATE IF MODEL DIRECTORY DOESNT EXIST
  filePath = os.path.join(model_dir,filename) # model/finalname
  joblib.dump(model,filePath)

save_model(model,'and.model')

loaded_model = joblib.load('model/and.model')

loaded_model.predict(inputs)

"""**OR TYPE** """

OR = {
    'x1':[0,0,1,1],
    'x2':[0,1,0,1],
    'y':[0,1,1,1],
}

df = pd.DataFrame(OR)
df

X,y = prepare_data(df)

ETA = 0.3 # 0 and 1
EPOCHS = 10

model_OR = perceptron(eta=ETA, epochs=EPOCHS)
model_OR.fit(X, y)

_ = model_OR.total_loss()

"""**XOR**"""

XOR = {
    'x1':[0,0,1,1],
    'x2':[0,1,0,1],
    'y':[0,1,1,0],
}

df = pd.DataFrame(XOR)
df

X,y = prepare_data(df)

ETA = 0.3 # 0 and 1
EPOCHS = 10

model_XOR = perceptron(eta=ETA, epochs=EPOCHS)
model_XOR.fit(X, y)

_ = model_XOR.total_loss()

"""In the XOR how much ever epoch we try to run the total loss at the end will be there. Like the other models the prediction and actual error wont match. We can see how much the weights are getting updated there is error. We can see this error by plotting a graph."""

def save_plot(df,file_name,model):
  def _create_base_plot(df):
    df.plot(kind='scatter',x='x1',y='x2',c='y',s=100,cmap='winter')
    plt.axhline(y=0,color='black',linestyle='--',linewidth=1)
    plt.axvline(x=0,color='black',linestyle='--',linewidth=1) 
    figure = plt.gcf() # get current figure
    figure.set_size_inches(10,8)



  def _plot_decision_regions(X,y,classfier,resolution = 0.02):
    colors = ('red','blue','lightgreen','yellow','cyan')
    cmap = ListedColormap(colors[:len(np.unique(y))])

    X = X.values #this is because we need the X values as array
    x1 = X[:,0] # Take all the rows but the first column only
    x2 = X[:,1] # Take all the rows but the 2nd column only
    x1_min,x1_max = x1.min()-1,x1.max() + 1
    x2_min,x2_max = x2.min()-1,x2.max() + 1

    xx1,xx2 = np.meshgrid(np.arange(x1_min,x1_max,resolution),
                          np.arange(x2_min,x2_max,resolution))
    
    print(xx1)
    print(xx1.ravel())
    
    Z = classfier.predict(np.array([xx1.ravel(),xx2.ravel()]).T) 
    Z = Z.reshape(xx1.shape)
    plt.contourf(xx1,xx2,Z,alpha=0.2,cmap=cmap)
    plt.xlim(xx1.min(),xx1.max())
    plt.xlim(xx2.min(),xx2.max()) 

    plt.plot()
    
  
  X,y = prepare_data(df)
  _create_base_plot(df)
  _plot_decision_regions(X,y,model)

  plot_dir = 'plots'
  os.makedirs(plot_dir,exist_ok=True)
  plotpath = os.path.join(plot_dir,file_name)
  plt.savefig(plotpath)

OR = {
    'x1':[0,0,1,1],
    'x2':[0,1,0,1],
    'y':[0,1,1,1],
}

df = pd.DataFrame(OR)
df

X,y = prepare_data(df)

ETA = 0.3 # 0 and 1
EPOCHS = 10

model_OR = perceptron(eta=ETA, epochs=EPOCHS)
model_OR.fit(X, y)

_ = model_OR.total_loss()

save_plot(df,'OR.png',model_OR)

AND = {
    'x1':[0,0,1,1],
    'x2':[0,1,0,1],
    'y':[0,0,0,1],
}

df = pd.DataFrame(AND)
df

X,y = prepare_data(df)

ETA = 0.3 # 0 and 1
EPOCHS = 10

model_AND = perceptron(eta=ETA, epochs=EPOCHS)
model_AND.fit(X, y)

_ = model_AND.total_loss()

save_plot(df,'AND.png',model_AND)



XOR = {
    'x1':[0,0,1,1],
    'x2':[0,1,0,1],
    'y':[0,1,1,0],
}

df = pd.DataFrame(XOR)
df

X,y = prepare_data(df)

ETA = 0.3 # 0 and 1
EPOCHS = 10

model_XOR = perceptron(eta=ETA, epochs=EPOCHS)
model_XOR.fit(X, y)

_ = model_XOR.total_loss()

save_plot(df,'XOR.png',model_XOR)

"""We can see that in the XOR we cannot seperate the two data points with a line. This is where the perceptron is failing. In the AND and OR we can seperate the data points with a linear line but not in XOR. XOR is not linear.

**NAND**
"""

NAND = {
    'x1':[0,0,1,1],
    'x2':[0,1,0,1],
    'y':[1,1,1,0],
}

df = pd.DataFrame(NAND)
df

X,y = prepare_data(df)

ETA = 0.3 # 0 and 1
EPOCHS = 10

model_NAND = perceptron(eta=ETA, epochs=EPOCHS)
model_NAND.fit(X, y)

_ = model_NAND.total_loss()

save_plot(df,'NAND.png',model_NAND)

